import os
from typing import TypedDict, Annotated, Sequence
from dotenv import load_dotenv
from langchain_openai import ChatOpenAI
from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder
from langchain_core.messages import BaseMessage, HumanMessage, AIMessage
from langgraph.graph import StateGraph, END
from skills import search_knowledge_base, query_order, get_product_info, get_refund_policy

load_dotenv()

ark_api_key = os.getenv("ARK_API_KEY").strip()
ark_base_url = os.getenv("ARK_BASE_URL").strip()
ark_chat_model = os.getenv("ARK_CHAT_MODEL").strip()

llm = ChatOpenAI(
    model=ark_chat_model,
    api_key=ark_api_key,
    base_url=ark_base_url,
    temperature=0.7
)

class AgentState(TypedDict):
    messages: Annotated[Sequence[BaseMessage], "add"]
    next: str
    question: str

supervisor_prompt = ChatPromptTemplate.from_messages([
    ("system", """ä½ æ˜¯ä¸€ä¸ªç”µå•†å®¢æœåè°ƒå‘˜ã€‚è¯·åˆ†æç”¨æˆ·çš„é—®é¢˜ï¼Œåˆ¤æ–­å®ƒå±äºä»¥ä¸‹å“ªä¸€ç±»ï¼š
[A. æŠ€æœ¯é—®é¢˜] - ç½‘ç«™æ•…éšœã€APPä½¿ç”¨é—®é¢˜ã€åŠŸèƒ½å¼‚å¸¸
[B. è®¢å•æŸ¥è¯¢] - è®¢å•çŠ¶æ€ã€ç‰©æµä¿¡æ¯ã€æ”¯ä»˜é—®é¢˜
[C. é€€æ¬¾å”®å] - é€€æ¬¾ç”³è¯·ã€é€€è´§æµç¨‹ã€å”®åæœåŠ¡
[D. äº§å“å’¨è¯¢] - å•†å“ä¿¡æ¯ã€åº“å­˜æŸ¥è¯¢ã€ä¿ƒé”€æ´»åŠ¨

è¯·åªå›å¤ç±»åˆ«ä»£å·ï¼ˆA/B/C/Dï¼‰ï¼Œä¸è¦å›å¤å…¶ä»–ä»»ä½•å†…å®¹ã€‚"""),
    ("human", "{question}")
])

tech_prompt = ChatPromptTemplate.from_messages([
    ("system", "ä½ æ˜¯ä¸€ä¸ªæŠ€æœ¯æ”¯æŒä¸“å®¶ï¼Œè¯·æ ¹æ®çŸ¥è¯†åº“ä¿¡æ¯å›ç­”ç”¨æˆ·çš„æŠ€æœ¯é—®é¢˜ã€‚ä½ å¯ä»¥ä½¿ç”¨ä»¥ä¸‹çŸ¥è¯†åº“ä¿¡æ¯ï¼š\n" + 
     "ç™»å½•é—®é¢˜ï¼šè¯·æ£€æŸ¥æ‚¨çš„ç”¨æˆ·åå’Œå¯†ç æ˜¯å¦æ­£ç¡®ï¼Œç¡®ä¿æ²¡æœ‰åŒºåˆ†å¤§å°å†™é”™è¯¯ã€‚å¦‚æœå¿˜è®°å¯†ç ï¼Œè¯·ç‚¹å‡»'å¿˜è®°å¯†ç 'è¿›è¡Œé‡ç½®ã€‚\n" +
     "APPå´©æºƒï¼šAPPå´©æºƒè¯·å°è¯•ä»¥ä¸‹æ­¥éª¤ï¼š1. æ¸…é™¤APPç¼“å­˜ï¼›2. æ›´æ–°åˆ°æœ€æ–°ç‰ˆæœ¬ï¼›3. é‡å¯è®¾å¤‡ã€‚å¦‚é—®é¢˜ä»ç„¶å­˜åœ¨ï¼Œè¯·è”ç³»æŠ€æœ¯æ”¯æŒã€‚"),
    ("human", "{input}")
])

order_prompt = ChatPromptTemplate.from_messages([
    ("system", "ä½ æ˜¯ä¸€ä¸ªè®¢å•æŸ¥è¯¢ä¸“å®¶ï¼Œè¯·å›ç­”ç”¨æˆ·çš„è®¢å•é—®é¢˜ã€‚ä½ å¯ä»¥æŸ¥è¯¢ä»¥ä¸‹ç¤ºä¾‹è®¢å•ï¼š\n" +
     "ORD001ï¼šçŠ¶æ€å·²å‘è´§ï¼Œç‰©æµé¡ºä¸°å¿«é€’SF1234567890ï¼Œé‡‘é¢Â¥299.00ï¼Œå•†å“æ— çº¿è“ç‰™è€³æœºx1\n" +
     "ORD002ï¼šçŠ¶æ€å¾…æ”¯ä»˜ï¼Œç‰©æµå°šæœªå‘è´§ï¼Œé‡‘é¢Â¥599.00ï¼Œå•†å“æ™ºèƒ½æ‰‹è¡¨x1\n" +
     "ORD003ï¼šçŠ¶æ€å·²å®Œæˆï¼Œç‰©æµå·²ç­¾æ”¶ï¼Œé‡‘é¢Â¥199.00ï¼Œå•†å“æ‰‹æœºå£³x2"),
    ("human", "{input}")
])

refund_prompt = ChatPromptTemplate.from_messages([
    ("system", "ä½ æ˜¯ä¸€ä¸ªé€€æ¬¾å”®åä¸“å®¶ï¼Œè¯·æŒ‡å¯¼ç”¨æˆ·å®Œæˆé€€æ¬¾ç”³è¯·æµç¨‹ã€‚é€€æ¬¾æ”¿ç­–å¦‚ä¸‹ï¼š\n" +
     "1. 7å¤©æ— ç†ç”±é€€æ¢ï¼šå•†å“æ”¶åˆ°å7å¤©å†…ï¼Œæœªä½¿ç”¨ä¸”åŒ…è£…å®Œå¥½å¯ç”³è¯·é€€æ¢\n" +
     "2. è´¨é‡é—®é¢˜ï¼š30å¤©å†…å‡ºç°è´¨é‡é—®é¢˜ï¼Œå¯å…è´¹é€€æ¢æˆ–ç»´ä¿®\n" +
     "3. é€€æ¬¾æµç¨‹ï¼šè¿›å…¥'æˆ‘çš„è®¢å•'â†’é€‰æ‹©è®¢å•â†’ç‚¹å‡»'ç”³è¯·é€€æ¬¾'â†’å¡«å†™åŸå› æäº¤â†’ç­‰å¾…å®¡æ ¸(1-3å·¥ä½œæ—¥)â†’æ¬¾é¡¹3-5å·¥ä½œæ—¥åŸè·¯è¿”å›"),
    ("human", "{input}")
])

product_prompt = ChatPromptTemplate.from_messages([
    ("system", "ä½ æ˜¯ä¸€ä¸ªäº§å“å’¨è¯¢ä¸“å®¶ï¼Œè¯·å›ç­”ç”¨æˆ·çš„äº§å“é—®é¢˜ã€‚äº§å“ä¿¡æ¯å¦‚ä¸‹ï¼š\n" +
     "æ— çº¿è“ç‰™è€³æœºï¼šä»·æ ¼Â¥299.00ï¼Œåº“å­˜å……è¶³(50ä»¶)ï¼Œè§„æ ¼ï¼šè“ç‰™5.3ï¼Œç»­èˆª24å°æ—¶ï¼Œä¸»åŠ¨é™å™ª\n" +
     "æ™ºèƒ½æ‰‹è¡¨ï¼šä»·æ ¼Â¥599.00ï¼Œåº“å­˜ç´§å¼ (3ä»¶)ï¼Œè§„æ ¼ï¼š1.4è‹±å¯¸å±å¹•ï¼Œå¿ƒç‡ç›‘æµ‹ï¼ŒGPSå®šä½\n" +
     "æ‰‹æœºå£³ï¼šä»·æ ¼Â¥99.00ï¼Œåº“å­˜å……è¶³(100ä»¶)ï¼Œè§„æ ¼ï¼šç¡…èƒ¶æè´¨ï¼Œé˜²æ‘”è®¾è®¡"),
    ("human", "{input}")
])

def supervisor_node(state: AgentState):
    print(f"\nã€åè°ƒå‘˜ã€‘æ­£åœ¨åˆ†æé—®é¢˜...")
    question = state["question"]
    response = llm.invoke(supervisor_prompt.format(question=question))
    category = response.content.strip()
    print(f"ã€åè°ƒå‘˜ã€‘é—®é¢˜åˆ†ç±»ä¸ºï¼š{category}")
    return {
        "messages": [response],
        "next": category
    }

def tech_node(state: AgentState):
    print(f"\nã€æŠ€æœ¯æ”¯æŒä¸“å®¶ã€‘æ­£åœ¨å¤„ç†...")
    question = state["question"]
    result = llm.invoke(tech_prompt.format(input=question))
    return {
        "messages": [AIMessage(content=result.content)],
        "next": "END"
    }

def order_node(state: AgentState):
    print(f"\nã€è®¢å•æŸ¥è¯¢ä¸“å®¶ã€‘æ­£åœ¨å¤„ç†...")
    question = state["question"]
    result = llm.invoke(order_prompt.format(input=question))
    return {
        "messages": [AIMessage(content=result.content)],
        "next": "END"
    }

def refund_node(state: AgentState):
    print(f"\nã€é€€æ¬¾å”®åä¸“å®¶ã€‘æ­£åœ¨å¤„ç†...")
    question = state["question"]
    result = llm.invoke(refund_prompt.format(input=question))
    return {
        "messages": [AIMessage(content=result.content)],
        "next": "END"
    }

def product_node(state: AgentState):
    print(f"\nã€äº§å“å’¨è¯¢ä¸“å®¶ã€‘æ­£åœ¨å¤„ç†...")
    question = state["question"]
    result = llm.invoke(product_prompt.format(input=question))
    return {
        "messages": [AIMessage(content=result.content)],
        "next": "END"
    }

def router(state: AgentState):
    return state["next"]

workflow = StateGraph(AgentState)

workflow.add_node("supervisor", supervisor_node)
workflow.add_node("tech_agent", tech_node)
workflow.add_node("order_agent", order_node)
workflow.add_node("refund_agent", refund_node)
workflow.add_node("product_agent", product_node)

workflow.set_entry_point("supervisor")

workflow.add_conditional_edges(
    "supervisor",
    router,
    {
        "A": "tech_agent",
        "B": "order_agent",
        "C": "refund_agent",
        "D": "product_agent",
        "END": END
    }
)

workflow.add_edge("tech_agent", END)
workflow.add_edge("order_agent", END)
workflow.add_edge("refund_agent", END)
workflow.add_edge("product_agent", END)

app = workflow.compile()

def process_question(question: str):
    initial_state = {
        "messages": [HumanMessage(content=question)],
        "question": question,
        "next": ""
    }
    
    result = app.invoke(initial_state)
    final_message = result["messages"][-1]
    return final_message.content

def main():
    print("=" * 70)
    print("ğŸ èœ‚ç¾¤å¼Agentæ™ºèƒ½å®¢æœç³»ç»Ÿ - çœŸæ­£ä½¿ç”¨LangChain + LangGraph")
    print("=" * 70)
    print("\næŠ€æœ¯æ ˆï¼š")
    print("  âœ… LangChain - LLMé›†æˆå’ŒPromptæ¨¡æ¿")
    print("  âœ… LangGraph - çŠ¶æ€æœºå·¥ä½œæµ")
    print("  âœ… è±†åŒ…å¤§æ¨¡å‹ - ç«å±±æ–¹èˆŸAPI")
    print("=" * 70)
    print("\nè¯·è¾“å…¥æ‚¨çš„é—®é¢˜ï¼ˆè¾“å…¥ 'quit' é€€å‡ºï¼‰ï¼š\n")
    
    while True:
        user_input = input("ç”¨æˆ·: ")
        
        if user_input.lower() in ['quit', 'exit', 'é€€å‡º']:
            print("\næ„Ÿè°¢ä½¿ç”¨ï¼Œå†è§ï¼")
            break
        
        try:
            response = process_question(user_input)
            print(f"\nå®¢æœ: {response}\n")
            print("-" * 70)
        except Exception as e:
            print(f"\nã€é”™è¯¯ã€‘å‘ç”Ÿå¼‚å¸¸: {str(e)}\n")
            print("-" * 70)

if __name__ == "__main__":
    main()
