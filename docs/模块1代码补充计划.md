# 模块1代码补充计划

> 根据《模块1测试场景设计计划.md》分析当前代码差距，制定补充计划
> 计划创建时间：2026-02-26

---

## 一、差距总览

| 模块 | 当前状态 | 需要补充 |
|------|---------|---------|
| semantic_matcher.py | action命名不一致 | 统一命名，调整逻辑 |
| llm_verifier.py | 输出格式简单 | 扩展字段，完善迭代机制 |
| cleaner.py | apply_result不完整 | 完善入库逻辑，添加结果输出 |
| test_module1_cleaner.py | 基础测试框架 | 完善测试逻辑 |

---

## 二、详细补充计划

### 2.1 semantic_matcher.py 修改

#### 修改点1：统一action命名

```python
# 当前代码
'match_result': {
    'action': 'new_item'  # 改为 'create'
}
'match_result': {
    'action': 'merge'     # 改为 'reuse'
}

# 程序匹配
'procedure_match': {
    'action': 'new_procedure'    # 改为 'create_procedure'
    'action': 'merge_procedure'  # 改为 'reuse_procedure'
}
```

#### 修改点2：调整batch_match逻辑

确保相似度>0.85的项进入LLM审核流程（不是直接判定）：

```python
# 当前逻辑（需要调整）
elif top_candidates[0]['similarity'] > self.SIMILARITY_HIGH:
    # 直接生成merge建议
    
# 调整后逻辑
# 相似度>0.85的项也进入merge_suggestions，但标记为需要LLM审核
```

#### 修改点3：调整procedure_match返回值

```python
# 确保返回值符合测试场景要求
{
    'existing_procedure': best_match,
    'similarity': round(best_sim, 2),
    'action': 'reuse_procedure' if best_sim > 0.80 else 'create_procedure'
}
```

---

### 2.2 llm_verifier.py 修改

#### 修改点1：更新Prompt模板

要求LLM输出符合测试场景规范的详细字段：

```json
{
  "review_status": "confirmed/adjusted/failed",
  "review_round": 1,
  "total_items": 224,
  "confirmed_items": 200,
  "adjusted_items": 24,
  "details": [
    {
      "suggestion_id": "M001",
      "is_same_item": true,
      "item_decision": "reuse",
      "item_reason": "审计项标题相同，是同一检查项",
      "is_same_procedure": true,
      "procedure_decision": "reuse",
      "procedure_reason": "审计程序相同",
      "dimension_adjustment": null,
      "confidence": "high"
    }
  ]
}
```

#### 修改点2：完善iterative_verify方法

```python
def iterative_verify(self, merge_result: Dict, max_iterations: int = 3) -> Dict:
    """
    迭代审核，最多3次循环
    - 3次内通过：返回verified=True的结果
    - 3次不通过：标记为failed_review，生成失败报告
    """
    for i in range(max_iterations):
        # 执行审核
        # 如果approved，返回结果
        # 如果有adjustments，应用调整并继续
    
    # 3次后仍未通过
    # 标记为failed_review
    # 生成失败报告
```

#### 修改点3：添加失败报告生成功能

```python
def generate_failure_report(self, merge_result: Dict, review_history: List) -> Dict:
    """生成LLM审核失败报告"""
    return {
        "status": "failed_review",
        "total_rounds": len(review_history),
        "initial_judgment": {...},  # 向量模型的初始判断
        "review_history": [...],     # 每次LLM审核的意见
        "adjustment_records": [...], # 系统的调整记录
        "recommended_action": "人工介入处理"
    }
```

---

### 2.3 cleaner.py 修改

#### 修改点1：完善apply_result方法

```python
def apply_result(self, result_json: str, approved: bool = True):
    """
    应用清洗结果到数据库
    
    处理逻辑：
    1. action='create': 新建审计项
    2. action='reuse': 复用已有审计项ID
       - procedure_decision='create_procedure': 新增审计程序
       - procedure_decision='reuse_procedure': 跳过
    3. 记录来源追溯
    """
    # 读取结果JSON
    # 遍历merge_suggestions
    # 根据action执行相应操作
    # 生成执行结果报告
```

#### 修改点2：添加最终执行结果输出

```python
def generate_execution_report(self, execution_results: List) -> Dict:
    """生成最终执行结果"""
    return {
        "execution_status": "success/partial/failed",
        "total_items": 224,
        "created_items": 50,
        "reused_items": 174,
        "created_procedures": 80,
        "reused_procedures": 318,
        "source_records": 224,
        "failed_items": [],
        "execution_time": "120.5s"
    }
```

#### 修改点3：支持场景2的强制LLM审核

```python
def clean_from_excel(self, file_path: str, output_json: str = None, 
                     skip_llm: bool = False, force_llm: bool = False):
    """
    参数说明：
    - skip_llm: 是否跳过LLM（场景1使用）
    - force_llm: 是否强制启用LLM（场景2使用，即使相似度=1.0也要审核）
    """
```

---

### 2.4 test_module1_cleaner.py 修改

#### 修改点1：场景2测试逻辑调整

```python
def test_02_duplicate_detection(self):
    """测试场景2：增量导入（完全重复）"""
    # 场景2要求所有224条都进入LLM审核流程
    # 修改：force_llm=True
    result = cleaner.clean_from_excel(file_path, skip_llm=False, force_llm=True)
    
    # 验证：
    # 1. 所有项都经过LLM审核
    # 2. LLM判定全部"是同一审计项"
    # 3. 最终动作是reuse
    # 4. 审计项数量不变，来源记录+224
```

#### 修改点2：场景3测试逻辑完善

```python
def test_03_semantic_matching_with_llm(self):
    """测试场景3：跨年度导入（向量+LLM迭代审核）"""
    # 验证点：
    # 1. 向量模型正确计算相似度
    # 2. LLM能识别误判（如"是否建立"vs"是否有效运作"）
    # 3. 迭代调整机制正常工作
    # 4. 3次内审核通过或标记为失败
```

#### 修改点3：场景4测试逻辑完善

```python
def test_04_procedure_accumulation(self):
    """测试场景4：审计动作积累验证"""
    # 验证点：
    # 1. 程序相似度<0.80时新增程序
    # 2. 程序相似度≥0.80时跳过
    # 3. 同一审计项可有多条来源记录
```

---

## 三、修改文件清单

| 文件路径 | 修改类型 | 优先级 |
|---------|---------|--------|
| `knowledge-work-plugins/it-audit/skills/1-audit-item-collector/scripts/semantic_matcher.py` | 修改 | 高 |
| `knowledge-work-plugins/it-audit/skills/1-audit-item-collector/scripts/llm_verifier.py` | 修改 | 高 |
| `knowledge-work-plugins/it-audit/skills/1-audit-item-collector/scripts/cleaner.py` | 修改 | 高 |
| `tests/test_module1_cleaner.py` | 修改 | 中 |

---

## 四、预期输出格式验证

### 4.1 向量模型输出格式（场景1-3通用）

```json
{
  "version": "1.0",
  "created_at": "2026-02-26T10:00:00",
  "source_file": "audit_items_2021.xlsx",
  "summary": {
    "total_new_items": 224,
    "total_existing_items": 0,
    "suggested_new_items": 224,
    "suggested_reuse_items": 0,
    "pending_review": 0
  },
  "merge_suggestions": [
    {
      "suggestion_id": "M001",
      "new_item": {
        "title": "是否建立IT治理委员会",
        "dimension": "信息技术治理",
        "procedure": "查阅成立发文"
      },
      "match_result": {
        "existing_item_id": null,
        "existing_title": null,
        "similarity": 0.0,
        "action": "create"
      },
      "procedure_match": null,
      "vector_confidence": "high"
    }
  ],
  "pending_review": []
}
```

### 4.2 LLM审核输出格式

```json
{
  "review_status": "confirmed",
  "review_round": 1,
  "total_items": 224,
  "confirmed_items": 224,
  "adjusted_items": 0,
  "details": [
    {
      "suggestion_id": "M001",
      "is_same_item": true,
      "item_decision": "reuse",
      "item_reason": "审计项标题完全相同，是同一检查项",
      "is_same_procedure": true,
      "procedure_decision": "reuse",
      "procedure_reason": "审计程序完全相同",
      "dimension_adjustment": null,
      "confidence": "high"
    }
  ]
}
```

### 4.3 最终执行结果格式

```json
{
  "execution_status": "success",
  "total_items": 224,
  "created_items": 50,
  "reused_items": 174,
  "created_procedures": 80,
  "reused_procedures": 318,
  "source_records": 224,
  "failed_items": [],
  "execution_time": "120.5s"
}
```

---

## 五、执行顺序建议

1. **第一步**：修改 `semantic_matcher.py`
   - 统一action命名
   - 调整batch_match逻辑

2. **第二步**：修改 `llm_verifier.py`
   - 更新Prompt模板
   - 完善iterative_verify方法
   - 添加失败报告生成

3. **第三步**：修改 `cleaner.py`
   - 完善apply_result方法
   - 添加执行结果输出
   - 支持force_llm参数

4. **第四步**：修改 `test_module1_cleaner.py`
   - 完善各场景测试逻辑

5. **第五步**：运行测试验证
   - 执行所有测试场景
   - 验证输出格式
   - 修复问题

---

## 六、风险与应对

| 风险 | 影响 | 应对措施 |
|------|------|---------|
| action命名修改影响其他模块 | 中 | 全局搜索确认影响范围 |
| LLM Prompt调整后输出不稳定 | 中 | 增加输出格式校验和重试 |
| 测试数据格式不符 | 低 | 检查并调整列名映射 |

---

**计划完成时间**：约2-3小时

**计划创建时间**：2026-02-26
