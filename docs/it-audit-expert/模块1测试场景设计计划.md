# 模块1测试场景设计计划

> 目标：使用两份审计清单测试数据清理逻辑（向量模型+LLM迭代审核）
> 测试数据：`tests/审计项对比分析详细表.xlsx` (224条，包含2021和2022年审计项)

## 测试程序位置

**主测试程序：** `tests/test_module1_cleaner.py`

**测试数据库：** `tests/test_data/test_it_audit.db`

**测试数据文件：**
- `训练材料/2021年网络安全专自查底稿.xls` - 2021年审计项数据
- `训练材料/审计项 -2022.xls` - 2022年审计项数据

**运行命令：**
```bash
python tests/test_module1_cleaner.py
```

**测试结果输出：** `tests/results/`

---

---

## 一、测试数据概况

### 1.1 数据结构

| 字段 | 说明 |
|------|------|
| 2021_ID / 2022_ID | 审计项编号 |
| 2021_维度 / 2022_维度 | 审计维度 |
| 2021_审计项 / 2022_审计项 | 审计项标题 |
| 2021_审计程序 / 2022_审计程序 | 审计程序 |
| 综合相似度 | 两年度审计项相似度（之前计算的，仅参考） |
| 匹配结论 / 处理建议 | 之前分析的结果（仅参考，不作为基准） |

### 1.2 数据特点

- **224条记录**：包含2021年和2022年的审计项对比
- **两列数据**：2021年审计项和2022年审计项
- **多维度覆盖**：IT治理、数据安全、系统开发等
- **用途**：提取2021和2022年数据分别导入，测试清洗流程

---

## 二、核心概念定义

### 2.1 处理动作定义

| 动作 | 审计项 | 审计程序 | 来源追溯 | 说明 |
|------|--------|----------|----------|------|
| **create** | 新建审计项 | 新建审计程序 | 新增记录 | 全新的审计项 |
| **reuse** | 复用已有审计项ID | 程序相似度<0.80则新增，≥0.80则跳过 | 新增记录 | 复用已有审计项 |

**说明**：
- 场景2（完全重复）使用 `reuse` 动作
- 场景3（跨年度相似）根据LLM判定使用 `create` 或 `reuse`
- 不存在单独的 `skip` 或 `merge` 动作

### 2.2 审核流程

```
向量模型初筛（计算相似度）
    ↓
LLM审核（对整个匹配结果进行审核）
    ↓
根据LLM意见调整
    ↓
LLM再审核（最多3次循环）
    ↓
执行最终动作（create 或 reuse）
```

**LLM审核范围**：
- 审计项是否应该合并（复用）
- 审计动作是否应该合并
- 维度分类是否合理

---

## 三、测试场景设计

### 场景1：首次导入（空数据库）

**目的**：验证基础导入功能

**步骤**：
1. 清空数据库（或新建测试数据库）
2. 从测试数据中提取2021年审计项（224条）并导入
3. 验证：
   - 所有审计项成功导入
   - 维度正确创建
   - 审计动作正确关联
   - 来源追溯记录完整

**预期结果**：
- 导入224条审计项
- 创建N个维度
- 所有审计项使用 `create` 动作
- 224条来源追溯记录

**向量模型输出（场景1）**：
```json
{
  "version": "1.0",
  "created_at": "2026-02-26T10:00:00",
  "source_file": "audit_items_2021.xlsx",
  "summary": {
    "total_new_items": 224,
    "total_existing_items": 0,
    "suggested_new_items": 224,
    "suggested_reuse_items": 0,
    "pending_review": 0
  },
  "merge_suggestions": [
    {
      "suggestion_id": "M001",
      "new_item": {
        "title": "是否建立IT治理委员会",
        "dimension": "信息技术治理",
        "procedure": "查阅成立发文"
      },
      "match_result": {
        "existing_item_id": null,
        "existing_title": null,
        "similarity": 0.0,
        "action": "create"
      },
      "procedure_match": null,
      "vector_confidence": "high"
    }
  ],
  "pending_review": []
}
```

**说明**：场景1没有已有数据，所有审计项都是 `create`，不需要LLM审核。

---

### 场景2：增量导入（完全重复）

**目的**：验证重复检测逻辑（向量模型初筛 + LLM最终判定）

**判定流程**：
```
向量模型初筛（相似度≈1.0）→ LLM审核 → 判定为同一审计项 → 执行reuse
```

**步骤**：
1. 在场景1基础上，再次导入相同的2021年审计项
2. 向量模型初筛：计算相似度≈1.0，建议`reuse`
3. **LLM审核**：对整个匹配结果进行审核
4. LLM确认："这是完全重复的审计项和动作，应该reuse"
5. 执行`reuse`动作
6. 记录来源追溯（同一条审计项有2条来源记录）

**预期结果**：
- 224条全部进入LLM审核流程
- 向量模型相似度≈1.0
- LLM判定：全部"是同一审计项"
- 最终动作：`reuse`（复用已有审计项）
- **审计项数量不变**，但每条审计项有**2条来源记录**

**向量模型输出（场景2）**：
```json
{
  "version": "1.0",
  "created_at": "2026-02-26T10:30:00",
  "source_file": "audit_items_2021.xlsx",
  "summary": {
    "total_new_items": 224,
    "total_existing_items": 224,
    "suggested_new_items": 0,
    "suggested_reuse_items": 224,
    "pending_review": 0
  },
  "merge_suggestions": [
    {
      "suggestion_id": "M001",
      "new_item": {
        "title": "是否建立IT治理委员会",
        "dimension": "信息技术治理",
        "procedure": "查阅成立发文"
      },
      "match_result": {
        "existing_item_id": "ITEM-001",
        "existing_title": "是否建立IT治理委员会",
        "similarity": 0.98,
        "action": "reuse"
      },
      "procedure_match": {
        "existing_procedure": "查阅成立发文",
        "similarity": 0.97,
        "action": "reuse_procedure"
      },
      "vector_confidence": "high"
    }
  ],
  "pending_review": []
}
```

**LLM审核输出（场景2）**：
```json
{
  "review_status": "confirmed",
  "review_round": 1,
  "total_items": 224,
  "confirmed_items": 224,
  "adjusted_items": 0,
  "details": [
    {
      "suggestion_id": "M001",
      "is_same_item": true,
      "item_decision": "reuse",
      "item_reason": "审计项标题完全相同，是同一检查项",
      "is_same_procedure": true,
      "procedure_decision": "reuse",
      "procedure_reason": "审计程序完全相同",
      "dimension_adjustment": null,
      "confidence": "high"
    }
  ]
}
```

**执行动作（场景2）**：
- **审计项**：`reuse`（复用已有ID，不新建）
- **审计程序**：`reuse_procedure`（程序相似度≥0.80，不新增）
- **来源追溯**：新增224条记录

---

### 场景3：跨年度导入（向量+LLM迭代审核流程）

**目的**：验证向量模型+LLM迭代审核的完整流程

**设计流程**：
```
向量模型初筛 → LLM审核 → 根据审核意见调整 → LLM再审核（循环）
                    ↑___________________________________|
```
- 最多3次循环
- 如果3次不通过，宣布导入失败，生成结果，人工介入处理

**步骤**：
1. 数据库已有2021年审计项（场景1导入的）
2. 从测试数据中提取2022年审计项（224条）并导入
3. 执行完整清洗流程：
   - 向量模型初筛（计算相似度）
   - LLM审核（验证向量模型的判断）
   - 根据LLM审核意见调整建议
   - LLM再审核（迭代循环，最多3次）
4. 验证输出结果

**验证点**：

| 相似度范围 | 向量模型判断 | LLM审核 | 迭代调整 | 最终动作 |
|-----------|-------------|---------|---------|---------|
| >0.85 | 建议reuse | 确认/调整 | 根据LLM意见调整 | reuse或create |
| 0.60-0.85 | pending_review | 判断 | 根据LLM意见调整 | 根据LLM建议决定 |
| <0.60 | create | 确认 | 无需调整 | create |

**预期结果**：
- 向量模型正确计算相似度
- LLM能识别向量模型的误判（如"是否建立"vs"是否有效运作"这种高相似但不应合并的情况）
- 迭代调整机制正常工作
- **3次内审核通过**：正常入库
- **3次不通过**：生成失败报告，等待人工介入

**向量模型输出示例（场景3 - 高相似）**：
```json
{
  "suggestion_id": "M001",
  "new_item": {
    "title": "是否建立IT治理委员会",
    "dimension": "信息技术治理",
    "procedure": "检查成立文件"
  },
  "match_result": {
    "existing_item_id": "ITEM-001",
    "existing_title": "是否建立IT治理委员会",
    "similarity": 0.92,
    "action": "reuse"
  },
  "procedure_match": {
    "existing_procedure": "查阅成立发文",
    "similarity": 0.75,
    "action": "create_procedure"
  },
  "vector_confidence": "high"
}
```

**LLM审核输出示例（场景3 - 需要调整）**：
```json
{
  "suggestion_id": "M001",
  "is_same_item": true,
  "item_decision": "reuse",
  "item_reason": "都是检查IT治理委员会是否建立，是同一审计项",
  "is_same_procedure": false,
  "procedure_decision": "create",
  "procedure_reason": "检查方法不同，应保留两个动作",
  "dimension_adjustment": null,
  "confidence": "high"
}
```

**执行动作（场景3 - 高相似）**：
- **审计项**：`reuse`（复用已有ID）
- **审计程序**：`create_procedure`（程序相似度<0.80，新增审计程序）
- **来源追溯**：新增记录

**向量模型输出示例（场景3 - 假阳性）**：
```json
{
  "suggestion_id": "M015",
  "new_item": {
    "title": "IT治理委员会是否有效运作",
    "dimension": "信息技术治理",
    "procedure": "查阅会议记录"
  },
  "match_result": {
    "existing_item_id": "ITEM-001",
    "existing_title": "是否建立IT治理委员会",
    "similarity": 0.88,
    "action": "reuse"
  },
  "procedure_match": {
    "existing_procedure": "查阅成立发文",
    "similarity": 0.70,
    "action": "create_procedure"
  },
  "vector_confidence": "high"
}
```

**LLM审核输出示例（场景3 - 假阳性被识别）**：
```json
{
  "suggestion_id": "M015",
  "is_same_item": false,
  "item_decision": "create",
  "item_reason": "一个是检查'是否建立'，一个是检查'是否有效运作'，检查重点不同，不是同一审计项",
  "is_same_procedure": false,
  "procedure_decision": "create",
  "procedure_reason": "检查对象不同",
  "dimension_adjustment": null,
  "confidence": "high"
}
```

**执行动作（场景3 - 假阳性调整后）**：
- **审计项**：`create`（新建审计项）
- **审计程序**：`create_procedure`（新建审计程序）
- **来源追溯**：新增记录

**失败处理**：
- 如果3次LLM审核后仍未通过，标记为`failed_review`
- 生成详细报告，包含：
  - 向量模型的初始判断
  - 每次LLM审核的意见
  - 系统的调整记录
  - 建议的人工处理方案

---

### 场景4：审计动作积累验证

**目的**：验证同一审计项下多个审计动作的积累

**步骤**：
1. 完成场景3的导入
2. 查询数据库中通过`reuse`导入的审计项
3. 验证审计动作是否正确积累

**验证点**：
- 选择2021年和2022年标题相同但审计程序不同的项
- 示例审计项："是否建立IT治理委员会"
  - 2021审计程序：查阅成立发文
  - 2022审计程序：检查成立文件
- 验证：
  1. 审计项只有一条（没有重复创建）
  2. 两个审计程序都保留（如果相似度<0.80）
  3. 来源追溯有2条记录（分别指向2021和2022的来源）

**数据库验证查询**：
```sql
-- 查询有多审计程序的审计项
SELECT 
    ai.id,
    ai.title,
    COUNT(ap.id) as procedure_count,
    GROUP_CONCAT(ap.procedure_text, ' | ') as procedures
FROM audit_items ai
JOIN audit_procedures ap ON ai.id = ap.item_id
GROUP BY ai.id
HAVING COUNT(ap.id) > 1;
```

**预期结果**：
- 存在审计项有2个审计程序
- 程序文本不同（如"查阅成立发文"和"检查成立文件"）

---

### 场景5：边界情况测试

**目的**：验证异常情况处理

#### 5.1 空审计程序
- 测试数据：审计程序为空的记录
- 验证：正确处理空值，不报错

#### 5.2 特殊字符
- 测试数据：包含换行、引号的审计项
- 验证：正确清洗和存储

#### 5.3 超长文本
- 测试数据：超过500字的审计项
- 验证：正确截断或存储

#### 5.4 维度变化
- 测试数据：同标题不同维度
- 验证：正确识别并记录

---

## 四、JSON格式规范

### 4.1 向量模型输出格式

```json
{
  "version": "1.0",
  "created_at": "ISO8601时间戳",
  "source_file": "源文件名",
  "summary": {
    "total_new_items": "新导入审计项总数",
    "total_existing_items": "数据库已有审计项数",
    "suggested_new_items": "建议create的数量",
    "suggested_reuse_items": "建议reuse的数量",
    "pending_review": "待LLM审核的数量"
  },
  "merge_suggestions": [
    {
      "suggestion_id": "M001",
      "new_item": {
        "title": "审计项标题",
        "dimension": "审计维度",
        "procedure": "审计程序"
      },
      "match_result": {
        "existing_item_id": "已有审计项ID（create时为null）",
        "existing_title": "已有审计项标题（create时为null）",
        "similarity": "相似度分数（0-1）",
        "action": "create 或 reuse"
      },
      "procedure_match": {
        "existing_procedure": "匹配的已有程序",
        "similarity": "程序相似度",
        "action": "create_procedure 或 reuse_procedure"
      },
      "vector_confidence": "high/medium/low"
    }
  ],
  "pending_review": [
    {
      "suggestion_id": "P001",
      "new_item": {...},
      "candidates": [...],
      "vector_confidence": "low"
    }
  ]
}
```

### 4.2 LLM审核输出格式

```json
{
  "review_status": "confirmed/adjusted/failed",
  "review_round": "审核轮次（1-3）",
  "total_items": "审核总数",
  "confirmed_items": "确认数",
  "adjusted_items": "调整数",
  "details": [
    {
      "suggestion_id": "M001",
      "is_same_item": "true/false",
      "item_decision": "create/reuse",
      "item_reason": "判断理由",
      "is_same_procedure": "true/false",
      "procedure_decision": "create/reuse",
      "procedure_reason": "判断理由",
      "dimension_adjustment": "null或建议维度",
      "confidence": "high/medium/low"
    }
  ]
}
```

### 4.3 最终执行结果格式

```json
{
  "execution_status": "success/partial/failed",
  "total_items": 224,
  "created_items": 50,
  "reused_items": 174,
  "created_procedures": 80,
  "reused_procedures": 318,
  "source_records": 224,
  "failed_items": [],
  "execution_time": "120.5s"
}
```

---

## 五、测试执行计划

### 5.1 测试脚本结构

```
tests/
├── test_module1_cleaner.py          # 主测试脚本
├── extract_test_data.py             # 数据提取脚本
├── test_data/
│   ├── audit_items_2021.xlsx       # 2021年审计项（提取）
│   └── audit_items_2022.xlsx       # 2022年审计项（提取）
└── results/
    └── test_results_*.json          # 测试结果输出
```

### 5.2 数据提取脚本

```python
# extract_test_data.py
# 从审计项对比分析详细表.xlsx中提取测试数据

import pandas as pd

def extract_2021_items():
    """提取2021年审计项"""
    df = pd.read_excel('tests/审计项对比分析详细表.xlsx')
    # 提取2021年数据（2021_ID, 2021_维度, 2021_审计项, 2021_审计程序）
    # 重命名为标准列名（维度, 审计项, 审计程序）
    # 保存为 tests/test_data/audit_items_2021.xlsx

def extract_2022_items():
    """提取2022年审计项"""
    df = pd.read_excel('tests/审计项对比分析详细表.xlsx')
    # 提取2022年数据（2022_ID, 2022_维度, 2022_审计项, 2022_审计程序）
    # 重命名为标准列名（维度, 审计项, 审计程序）
    # 保存为 tests/test_data/audit_items_2022.xlsx
```

### 5.3 测试脚本功能

```python
# 测试脚本核心功能

class TestModule1Cleaner:
    """模块1清洗流程测试"""
    
    def test_01_first_import(self):
        """测试首次导入（空数据库）"""
        pass
    
    def test_02_duplicate_detection(self):
        """测试重复检测（完全重复）"""
        pass
    
    def test_03_semantic_matching_with_llm(self):
        """测试向量+LLM迭代审核流程（跨年度导入）"""
        pass
    
    def test_04_procedure_accumulation(self):
        """测试审计动作积累"""
        pass
    
    def test_05_edge_cases(self):
        """测试边界情况"""
        pass
```

---

## 六、成功标准

### 6.1 功能正确性

| 测试项 | 通过标准 |
|--------|---------|
| 首次导入 | 100%成功导入，无报错 |
| 重复检测 | 100%识别重复项，不新建审计项，来源记录+224条 |
| 向量+LLM迭代审核 | 向量模型计算相似度，LLM能识别误判，迭代调整机制正常工作，3次内通过 |
| 审计动作积累 | 程序相似度<0.80时新增程序，≥0.80时跳过 |
| 来源追溯 | 每次导入都记录，同一条审计项可有多条来源 |

### 6.2 性能指标

| 指标 | 目标值 |
|------|--------|
| 向量计算速度 | 224条×224条 < 30秒 |
| LLM调用次数 | 每轮审核 < 10次（批量调用） |
| 总处理时间 | 224条 < 2分钟（不含LLM）|

---

## 七、风险与应对

| 风险 | 影响 | 应对措施 |
|------|------|---------|
| 模型未下载 | 无法测试 | 提前运行download_model.py |
| LLM API不可用 | 无法测试LLM审核 | 使用mock模式测试向量模型部分 |
| 数据格式不符 | 解析失败 | 检查并调整列名映射 |
| 相似度阈值不准 | 匹配不准确 | 根据测试结果调整阈值 |

---

## 八、执行步骤

1. **数据准备**（30分钟）
   - 运行数据提取脚本，生成2021和2022年测试数据
   - 准备测试数据库

2. **场景1测试**（30分钟）
   - 首次导入2021年数据
   - 验证导入结果

3. **场景2测试**（30分钟）
   - 重复导入2021年数据
   - 验证重复检测和来源追溯

4. **场景3测试**（1小时）
   - 导入2022年数据（向量+LLM迭代审核流程）
   - 验证相似度计算、LLM审核、迭代调整机制

5. **场景4测试**（30分钟）
   - 验证审计动作积累

6. **场景5测试**（30分钟）
   - 边界情况测试

7. **报告生成**（30分钟）
   - 汇总测试结果
   - 输出测试报告

---

**计划完成时间**：约4-5小时

**计划创建时间**：2026-02-26

**最后更新时间**：2026-02-26
