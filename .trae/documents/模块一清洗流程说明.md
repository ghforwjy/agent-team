# 模块一清洗流程详细说明

## 用户问题

> 初筛是什么意思？200条记录，每条可能对应3条候选，变成600条，然后统一提交给大模型判断？

## 详细解释

### 初筛逻辑

**不是每条都有3个候选！**

```
200条新审计项
    │
    ▼
向量模型计算相似度（与600条已有审计项比较）
    │
    ▼
筛选结果：
    │
    ├─ 相似度 < 0.60：无候选 → 直接作为新审计项入库
    │   （假设有100条，占比50%）
    │
    ├─ 相似度 0.60-0.85：有候选 → 标记为"待人工确认"
    │   （假设有50条，占比25%）
    │
    └─ 相似度 > 0.85：有候选 → 需要LLM校验
        （假设有50条，占比25%）
```

### 实际数据流

```
输入: 200条新审计项

阶段1: 向量模型初筛
┌─────────────────────────────────────────────────────────────────┐
│ 200条新审计项 × 600条已有审计项                                  │
│ = 矩阵乘法一次性计算所有相似度                                    │
│ = 约10秒完成                                                    │
└────────────────────────────┬────────────────────────────────────┘
                             │
                             ▼
┌─────────────────────────────────────────────────────────────────┐
│ 筛选结果：                                                       │
│                                                                  │
│ 100条 → 相似度<0.60 → 直接新增（无需LLM）                        │
│                                                                  │
│ 50条 → 相似度0.60-0.85 → 待人工确认（可选LLM辅助）               │
│                                                                  │
│ 50条 → 相似度>0.85 → 需要LLM校验                                 │
│        每条最多3个候选 = 最多150对                               │
│        但实际高相似候选可能只有1-2个                             │
│        假设实际需要校验的是 50对                                 │
└────────────────────────────┬────────────────────────────────────┘
                             │
                             ▼
阶段2: LLM批量校验
┌─────────────────────────────────────────────────────────────────┐
│ 50对候选 → 分批提交给LLM                                         │
│ 每批10对 = 5次LLM调用                                           │
│ 每次调用约0.1元 = 总成本约0.5元                                  │
└─────────────────────────────────────────────────────────────────┘
```

### 关键点澄清

| 误解 | 正确理解 |
|------|----------|
| 200条每条都有3个候选 | 只有相似度>0.60的才有候选，很多可能是0候选 |
| 600条全部提交LLM | 只有相似度>0.85的才需要LLM，实际可能只有50对 |
| 每对单独调用LLM | 批量提交，一次处理10对，减少调用次数 |

### 为什么用Top-K=3？

```
新审计项: "公司是否建立IT治理委员会"

向量匹配结果（Top-3）:
  候选1: "是否设立IT治理委员会" → 相似度 0.92
  候选2: "IT治理委员会是否有效运作" → 相似度 0.88
  候选3: "是否制定IT治理制度" → 相似度 0.75

处理方式:
  候选1 (0.92 > 0.85) → LLM校验是否合并
  候选2 (0.88 > 0.85) → LLM校验是否合并
  候选3 (0.75 < 0.85) → 不需要LLM，人工确认即可
```

### LLM批量校验示例

```python
# 一次LLM调用处理10对候选
prompt = """
请判断以下10对审计项是否应该合并：

1. 新: "公司是否建立IT治理委员会" vs 已有: "是否设立IT治理委员会" (相似度0.92)
2. 新: "公司是否建立IT治理委员会" vs 已有: "IT治理委员会是否有效运作" (相似度0.88)
3. 新: "是否制定网络安全策略" vs 已有: "是否建立信息安全方针" (相似度0.91)
...

请以JSON格式输出：
[
  {"index": 1, "should_merge": true, "reason": "同一检查项"},
  {"index": 2, "should_merge": false, "reason": "检查重点不同"},
  ...
]
"""
```

### 成本估算

| 场景 | 向量计算 | LLM调用 | 总成本 |
|------|----------|---------|--------|
| 200条新，600条已有 | 10秒，0元 | 5次，0.5元 | 0.5元 |
| 1000条新，600条已有 | 30秒，0元 | 20次，2元 | 2元 |

## 总结

1. **初筛**：向量模型快速找出候选，不是每条都有候选
2. **筛选**：只有相似度>0.85的才需要LLM校验
3. **批量**：多个候选对合并到一次LLM调用中
4. **成本**：从可能的几万元降到几毛钱
